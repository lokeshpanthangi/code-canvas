import { useState, useEffect, useRef } from 'react';
import { Link } from 'react-router-dom';
import Navbar from '@/components/layout/Navbar';
import Footer from '@/components/layout/Footer';
import { CodeBlock, Callout, OutputBlock, InlineCode } from '@/components/project/CodeBlock';
import { 
  ChevronRight, 
  Clock, 
  Users, 
  Star, 
  GitFork,
  ArrowLeft,
  Github,
  BookOpen,
  List,
  ExternalLink,
  CheckCircle2,
  Circle,
  Download,
  Loader2
} from 'lucide-react';
import { Button } from '@/components/ui/button';

const sections = [
  { id: 'overview', title: 'Overview' },
  { id: 'what-is-chatbot', title: 'What is a Chatbot?' },
  { id: 'how-memory-works', title: 'How Memory Works' },
  { id: 'prerequisites', title: 'Prerequisites' },
  { id: 'setup', title: 'Setup & Installation' },
  { id: 'env-setup', title: 'API Key & Environment', parent: 'setup' },
  { id: 'implementation', title: 'Implementation' },
  { id: 'basic-chat', title: 'Basic Chat Call', parent: 'implementation' },
  { id: 'prompt-template', title: 'Prompt Templates', parent: 'implementation' },
  { id: 'adding-memory', title: 'Adding Memory', parent: 'implementation' },
  { id: 'streaming', title: 'Streaming Responses', parent: 'implementation' },
  { id: 'complete-chatbot', title: 'Complete Chatbot' },
  { id: 'testing', title: 'Testing It Out' },
  { id: 'next-steps', title: 'Next Steps' },
];

const BasicChatbot = () => {
  const [activeSection, setActiveSection] = useState('overview');
  const [sidebarOpen, setSidebarOpen] = useState(false);
  const [progress, setProgress] = useState<string[]>([]);
  const [isDownloading, setIsDownloading] = useState(false);
  const contentRef = useRef<HTMLElement>(null);

  // Download function
  const handleDownloadPDF = async () => {
    setIsDownloading(true);

    const pdfContent = `
BUILD A BASIC CHATBOT WITH LANGCHAIN
======================================

A step-by-step guide to building a conversational AI chatbot with memory using LangChain and OpenAI.

Difficulty: Beginner
Estimated Time: 2 hours

TABLE OF CONTENTS
-----------------
1. Overview
2. What is a Chatbot?
3. How Memory Works
4. Prerequisites
5. Setup & Installation
   - API Key & Environment
6. Implementation
   - Basic Chat Call
   - Prompt Templates
   - Adding Memory
   - Streaming Responses
7. Complete Chatbot
8. Testing It Out
9. Next Steps

---
Generated by MLCodex.dev
Build a Basic Chatbot
`;

    const blob = new Blob([pdfContent], { type: 'text/plain' });
    const url = URL.createObjectURL(blob);
    const link = document.createElement('a');
    link.href = url;
    link.download = 'basic-chatbot-langchain.txt';
    document.body.appendChild(link);
    link.click();
    document.body.removeChild(link);
    URL.revokeObjectURL(url);

    setTimeout(() => {
      setIsDownloading(false);
    }, 1000);
  };

  // Track scroll position for active section
  useEffect(() => {
    const handleScroll = () => {
      const sectionElements = sections.map(s => ({
        id: s.id,
        element: document.getElementById(s.id)
      })).filter(s => s.element);

      for (const section of sectionElements.reverse()) {
        if (section.element) {
          const rect = section.element.getBoundingClientRect();
          if (rect.top <= 120) {
            setActiveSection(section.id);
            break;
          }
        }
      }
    };

    window.addEventListener('scroll', handleScroll);
    return () => window.removeEventListener('scroll', handleScroll);
  }, []);

  const scrollToSection = (id: string) => {
    const element = document.getElementById(id);
    if (element) {
      const offset = 100;
      const elementPosition = element.getBoundingClientRect().top + window.scrollY;
      window.scrollTo({ top: elementPosition - offset, behavior: 'smooth' });
    }
  };

  const toggleProgress = (sectionId: string) => {
    setProgress(prev =>
      prev.includes(sectionId)
        ? prev.filter(id => id !== sectionId)
        : [...prev, sectionId]
    );
  };

  return (
    <div className="min-h-screen bg-background relative">
      <div className="noise-overlay" />
      <Navbar variant="simple" />

      <main className="pt-24 pb-20" ref={contentRef}>
        <div className="container mx-auto px-6">
          {/* Breadcrumb */}
          <div className="flex items-center gap-2 text-sm text-muted-foreground mb-8">
            <Link to="/docs" className="hover:text-foreground transition-colors">Docs</Link>
            <ChevronRight className="w-4 h-4" />
            <span className="text-foreground">Build a Basic Chatbot</span>
          </div>

          <div className="flex gap-8 lg:gap-12">
            {/* Left Sidebar - Other Docs (Desktop) */}
            <aside className="hidden lg:block w-64 shrink-0">
              <div className="sticky top-28">
                <div className="flex items-center gap-2 mb-4">
                  <BookOpen className="w-4 h-4 text-muted-foreground" />
                  <span className="text-sm font-medium text-foreground">Gen AI Modules</span>
                </div>
                <nav className="space-y-1">
                  {[
                    { slug: 'basic-chatbot', title: 'Build a Basic Chatbot', active: true },
                    { slug: 'basic-rag', title: 'Implement Basic RAG' },
                    { slug: 'small-agent', title: 'Build a Small Agent' },
                    { slug: 'prompt-engineering', title: 'Prompt Engineering Patterns' },
                  ].map((doc) => (
                    <Link
                      key={doc.slug}
                      to={`/docs/${doc.slug}`}
                      className={`block py-1.5 text-sm transition-colors ${
                        doc.active
                          ? 'text-teal-500 font-medium'
                          : 'text-muted-foreground hover:text-foreground'
                      }`}
                    >
                      {doc.title}
                    </Link>
                  ))}
                </nav>

                {/* View All Docs */}
                <Link
                  to="/docs"
                  className="flex items-center gap-2 mt-4 text-sm text-muted-foreground hover:text-foreground transition-colors"
                >
                  View all modules
                  <ChevronRight className="w-4 h-4" />
                </Link>

                {/* Progress Tracker */}
                <div className="mt-8 pt-6 border-t border-border">
                  <div className="text-sm font-medium text-foreground mb-3">Your Progress</div>
                  <div className="text-xs text-muted-foreground mb-2">
                    {progress.length} / {sections.filter(s => !s.parent).length} sections completed
                  </div>
                  <div className="w-full h-2 rounded-full bg-foreground/10">
                    <div
                      className="h-full rounded-full bg-gradient-to-r from-teal-500 to-cyan-500 transition-all"
                      style={{ width: `${(progress.length / sections.filter(s => !s.parent).length) * 100}%` }}
                    />
                  </div>
                </div>

                {/* Quick Actions */}
                <div className="mt-6 pt-6 border-t border-border">
                  <div className="text-sm font-medium text-foreground mb-3">Quick Actions</div>
                  <div className="space-y-2">
                    <a
                      href="https://github.com"
                      target="_blank"
                      rel="noopener noreferrer"
                      className="flex items-center gap-2 text-sm text-muted-foreground hover:text-foreground transition-colors py-1"
                    >
                      <Github className="w-4 h-4" />
                      View Source
                    </a>
                    <button
                      onClick={handleDownloadPDF}
                      disabled={isDownloading}
                      className="flex items-center gap-2 text-sm text-muted-foreground hover:text-foreground transition-colors py-1 disabled:opacity-50"
                    >
                      {isDownloading ? (
                        <Loader2 className="w-4 h-4 animate-spin" />
                      ) : (
                        <Download className="w-4 h-4" />
                      )}
                      {isDownloading ? 'Downloading...' : 'Download PDF'}
                    </button>
                  </div>
                </div>
              </div>
            </aside>

            {/* Main Content */}
            <article className="flex-1 min-w-0 max-w-4xl">
              {/* Header */}
              <header className="mb-12">
                <div className="mb-6">
                  <h1 className="text-4xl lg:text-5xl font-bold tracking-tight mb-4">
                    Build a Basic Chatbot
                  </h1>
                  <p className="text-lg text-muted-foreground leading-relaxed">
                    Create a conversational AI chatbot from scratch using LangChain and OpenAI. Learn how to
                    manage chat history, use prompt templates, and stream responses in real time.
                  </p>
                </div>

                {/* Meta Info */}
                <div className="flex flex-wrap items-center gap-6 text-sm text-muted-foreground mb-6">
                  <div className="flex items-center gap-1.5">
                    <Clock className="w-4 h-4" />
                    <span>2 hours</span>
                  </div>
                  <div className="flex items-center gap-1.5">
                    <Star className="w-4 h-4" />
                    <span>1,204 stars</span>
                  </div>
                  <div className="flex items-center gap-1.5">
                    <GitFork className="w-4 h-4" />
                    <span>438 forks</span>
                  </div>
                  <div className="flex items-center gap-1.5">
                    <Users className="w-4 h-4" />
                    <span>89 contributors</span>
                  </div>
                  <span className="px-2.5 py-1 rounded-full bg-emerald-400/10 text-emerald-400 border border-emerald-400/20 text-xs font-medium">
                    Beginner
                  </span>
                </div>

                {/* Action Buttons */}
                <div className="flex flex-wrap gap-3">
                  <Button variant="hero" size="lg">
                    <Github className="w-4 h-4 mr-2" />
                    View on GitHub
                  </Button>
                  <Button
                    variant="outline"
                    size="lg"
                    className="border-foreground/20 hover:bg-foreground/5"
                    onClick={handleDownloadPDF}
                    disabled={isDownloading}
                  >
                    {isDownloading ? (
                      <Loader2 className="w-4 h-4 mr-2 animate-spin" />
                    ) : (
                      <Download className="w-4 h-4 mr-2" />
                    )}
                    {isDownloading ? 'Downloading...' : 'Download PDF'}
                  </Button>
                </div>
              </header>

              {/* ==================== OVERVIEW ==================== */}
              <section id="overview" className="mb-16">
                <h2 className="text-2xl font-bold text-foreground mb-4 flex items-center gap-3">
                  <button
                    onClick={() => toggleProgress('overview')}
                    className="text-muted-foreground hover:text-teal-500 transition-colors"
                  >
                    {progress.includes('overview') ? (
                      <CheckCircle2 className="w-6 h-6 text-teal-500" />
                    ) : (
                      <Circle className="w-6 h-6" />
                    )}
                  </button>
                  Overview
                </h2>
                <p className="text-muted-foreground leading-relaxed mb-4">
                  In this module, you'll build a fully working chatbot that remembers your conversation, responds
                  intelligently, and streams text in real time â€” all powered by <InlineCode>LangChain</InlineCode> and 
                  the <InlineCode>OpenAI</InlineCode> API. By the end you'll have a terminal-based chatbot that you
                  can extend into a web app, a Slack bot, or anything else.
                </p>
                <p className="text-muted-foreground leading-relaxed mb-4">
                  We'll start from absolute zero: installing libraries, saving your API key securely, and
                  understanding what a chatbot actually is under the hood. Then we'll layer on features one
                  step at a time so you can see exactly what each piece does.
                </p>

                <div className="grid grid-cols-1 md:grid-cols-3 gap-4 mt-8">
                  <div className="p-4 rounded-xl bg-card/50 border border-border">
                    <div className="text-2xl font-bold text-foreground mb-1">~80</div>
                    <div className="text-sm text-muted-foreground">Lines of Code</div>
                  </div>
                  <div className="p-4 rounded-xl bg-card/50 border border-border">
                    <div className="text-2xl font-bold text-foreground mb-1">âˆž</div>
                    <div className="text-sm text-muted-foreground">Conversation Memory</div>
                  </div>
                  <div className="p-4 rounded-xl bg-card/50 border border-border">
                    <div className="text-2xl font-bold text-foreground mb-1">3</div>
                    <div className="text-sm text-muted-foreground">Core Concepts</div>
                  </div>
                </div>
              </section>

              {/* ==================== WHAT IS A CHATBOT? ==================== */}
              <section id="what-is-chatbot" className="mb-16">
                <h2 className="text-2xl font-bold text-foreground mb-4 flex items-center gap-3">
                  <button
                    onClick={() => toggleProgress('what-is-chatbot')}
                    className="text-muted-foreground hover:text-teal-500 transition-colors"
                  >
                    {progress.includes('what-is-chatbot') ? (
                      <CheckCircle2 className="w-6 h-6 text-teal-500" />
                    ) : (
                      <Circle className="w-6 h-6" />
                    )}
                  </button>
                  What is a Chatbot?
                </h2>
                <p className="text-muted-foreground leading-relaxed mb-4">
                  A <strong className="text-foreground">chatbot</strong> is a program that takes user messages as input
                  and produces natural-language replies. Modern chatbots are powered by <strong className="text-foreground">Large Language Models (LLMs)</strong> like
                  GPT-4, which can understand context, follow instructions, and generate human-like text.
                </p>
                <p className="text-muted-foreground leading-relaxed mb-4">
                  At its core, a chatbot does three things:
                </p>

                <div className="grid grid-cols-1 md:grid-cols-3 gap-4 my-6">
                  <div className="p-4 rounded-xl bg-blue-500/10 border border-blue-500/20">
                    <div className="font-semibold text-blue-400 mb-1">1. Receive</div>
                    <div className="text-sm text-muted-foreground">Accept user input â€” a question, a command, or casual conversation</div>
                  </div>
                  <div className="p-4 rounded-xl bg-purple-500/10 border border-purple-500/20">
                    <div className="font-semibold text-purple-400 mb-1">2. Think</div>
                    <div className="text-sm text-muted-foreground">Send the message (+ history) to an LLM and let it reason out a response</div>
                  </div>
                  <div className="p-4 rounded-xl bg-emerald-500/10 border border-emerald-500/20">
                    <div className="font-semibold text-emerald-400 mb-1">3. Reply</div>
                    <div className="text-sm text-muted-foreground">Return the LLM's response to the user, optionally streaming it token-by-token</div>
                  </div>
                </div>

                <p className="text-muted-foreground leading-relaxed">
                  The magic ingredient that separates a chatbot from a single Q&A call is <strong className="text-foreground">memory</strong>.
                  Without memory the model has no idea what you said two messages ago. Let's dive into how that works.
                </p>
              </section>

              {/* ==================== HOW MEMORY WORKS ==================== */}
              <section id="how-memory-works" className="mb-16">
                <h2 className="text-2xl font-bold text-foreground mb-4 flex items-center gap-3">
                  <button
                    onClick={() => toggleProgress('how-memory-works')}
                    className="text-muted-foreground hover:text-teal-500 transition-colors"
                  >
                    {progress.includes('how-memory-works') ? (
                      <CheckCircle2 className="w-6 h-6 text-teal-500" />
                    ) : (
                      <Circle className="w-6 h-6" />
                    )}
                  </button>
                  How Memory Works
                </h2>
                <p className="text-muted-foreground leading-relaxed mb-4">
                  LLMs are <strong className="text-foreground">stateless</strong> â€” every API call is independent.
                  The model doesn't remember anything between requests. To create the illusion of a continuous
                  conversation we need to send the <em>entire chat history</em> with every new message.
                </p>

                {/* Visual Diagram */}
                <div className="my-8 p-8 rounded-2xl bg-card/50 border border-border">
                  <div className="text-center">
                    <div className="flex items-center justify-center gap-4 sm:gap-8 mb-6 flex-wrap">
                      {/* User Message */}
                      <div className="flex flex-col items-center gap-2">
                        <div className="text-xs text-muted-foreground mb-1">Your message</div>
                        <div className="px-4 py-2 rounded-lg bg-blue-500/20 border border-blue-500/40 text-blue-400 text-sm font-mono">
                          "Hi!"
                        </div>
                      </div>

                      <div className="text-muted-foreground/30 text-lg">+</div>

                      {/* History */}
                      <div className="flex flex-col items-center gap-2">
                        <div className="text-xs text-muted-foreground mb-1">Past messages</div>
                        <div className="px-4 py-2 rounded-lg bg-purple-500/20 border border-purple-500/40 text-purple-400 text-sm font-mono">
                          [history]
                        </div>
                      </div>

                      <div className="text-muted-foreground/30 text-lg">â†’</div>

                      {/* LLM */}
                      <div className="flex flex-col items-center gap-2">
                        <div className="text-xs text-muted-foreground mb-1">LLM</div>
                        <div className="px-4 py-2 rounded-lg bg-amber-500/20 border border-amber-500/40 text-amber-400 text-sm font-mono">
                          GPT-4
                        </div>
                      </div>

                      <div className="text-muted-foreground/30 text-lg">â†’</div>

                      {/* Response */}
                      <div className="flex flex-col items-center gap-2">
                        <div className="text-xs text-muted-foreground mb-1">Response</div>
                        <div className="px-4 py-2 rounded-lg bg-emerald-500/20 border border-emerald-500/40 text-emerald-400 text-sm font-mono">
                          "Hello!"
                        </div>
                      </div>
                    </div>
                    <p className="text-sm text-muted-foreground">
                      Every request bundles the full conversation history so the model stays in context
                    </p>
                  </div>
                </div>

                <p className="text-muted-foreground leading-relaxed mb-4">
                  LangChain makes this painless. It provides a <InlineCode>ChatMessageHistory</InlineCode> object
                  that automatically tracks Human and AI messages, and a <InlineCode>RunnableWithMessageHistory</InlineCode> wrapper
                  that injects the history into every call. You write the logic once
                  and LangChain handles the plumbing.
                </p>

                <Callout type="info" title="Token limits">
                  Chat history grows with every turn. For very long conversations you'll eventually hit the
                  model's context window. Strategies like summarisation or sliding-window trimming can help â€” 
                  but for a beginner chatbot, in-memory history works great.
                </Callout>
              </section>

              {/* ==================== PREREQUISITES ==================== */}
              <section id="prerequisites" className="mb-16">
                <h2 className="text-2xl font-bold text-foreground mb-4 flex items-center gap-3">
                  <button
                    onClick={() => toggleProgress('prerequisites')}
                    className="text-muted-foreground hover:text-teal-500 transition-colors"
                  >
                    {progress.includes('prerequisites') ? (
                      <CheckCircle2 className="w-6 h-6 text-teal-500" />
                    ) : (
                      <Circle className="w-6 h-6" />
                    )}
                  </button>
                  Prerequisites
                </h2>
                <p className="text-muted-foreground leading-relaxed mb-4">
                  This is a beginner-friendly module. You just need:
                </p>
                <ul className="space-y-3 text-muted-foreground">
                  <li className="flex items-start gap-3">
                    <ChevronRight className="w-5 h-5 text-teal-500 shrink-0 mt-0.5" />
                    <span><strong className="text-foreground">Python 3.9+</strong> â€” installed on your machine</span>
                  </li>
                  <li className="flex items-start gap-3">
                    <ChevronRight className="w-5 h-5 text-teal-500 shrink-0 mt-0.5" />
                    <span><strong className="text-foreground">An OpenAI API key</strong> â€” sign up at <InlineCode>platform.openai.com</InlineCode> and generate a key</span>
                  </li>
                  <li className="flex items-start gap-3">
                    <ChevronRight className="w-5 h-5 text-teal-500 shrink-0 mt-0.5" />
                    <span><strong className="text-foreground">Basic Python knowledge</strong> â€” variables, functions, and f-strings</span>
                  </li>
                </ul>

                <Callout type="tip" title="No ML experience needed!">
                  You don't need to know how LLMs work internally. We're treating the model as a service â€” you
                  send text in and get text out. That's it!
                </Callout>
              </section>

              {/* ==================== SETUP & INSTALLATION ==================== */}
              <section id="setup" className="mb-16">
                <h2 className="text-2xl font-bold text-foreground mb-4 flex items-center gap-3">
                  <button
                    onClick={() => toggleProgress('setup')}
                    className="text-muted-foreground hover:text-teal-500 transition-colors"
                  >
                    {progress.includes('setup') ? (
                      <CheckCircle2 className="w-6 h-6 text-teal-500" />
                    ) : (
                      <Circle className="w-6 h-6" />
                    )}
                  </button>
                  Setup & Installation
                </h2>
                <p className="text-muted-foreground leading-relaxed mb-4">
                  Let's start by creating a project folder and installing the two packages we need:
                  <InlineCode>langchain</InlineCode> (the orchestration framework) and 
                  <InlineCode>langchain-openai</InlineCode> (the OpenAI integration).
                </p>

                <CodeBlock
                  language="bash"
                  filename="terminal"
                  code={`# Create a new project folder
mkdir chatbot && cd chatbot

# (Optional) Create a virtual environment
python -m venv venv
source venv/bin/activate   # On Windows: venv\\Scripts\\activate

# Install dependencies
pip install langchain langchain-openai python-dotenv`}
                  showLineNumbers={false}
                />

                <Callout type="info" title="Why these packages?">
                  <strong>langchain</strong> â€” provides chains, memory, prompt templates, and the glue to
                  connect everything together.<br />
                  <strong>langchain-openai</strong> â€” the official LangChain â†” OpenAI bridge that gives us 
                  <InlineCode>ChatOpenAI</InlineCode>.<br />
                  <strong>python-dotenv</strong> â€” loads your API key from a <InlineCode>.env</InlineCode> file
                  so you never hard-code secrets.
                </Callout>

                {/* API Key & .env */}
                <div id="env-setup" className="mt-12">
                  <h3 className="text-xl font-semibold text-foreground mb-4">API Key & Environment</h3>
                  <p className="text-muted-foreground leading-relaxed mb-4">
                    Create a <InlineCode>.env</InlineCode> file in your project root and paste your OpenAI key:
                  </p>

                  <CodeBlock
                    filename=".env"
                    code={`OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx`}
                    showLineNumbers={false}
                  />

                  <Callout type="warning" title="Keep your key safe!">
                    Never commit <InlineCode>.env</InlineCode> to version control. Add it to your 
                    <InlineCode>.gitignore</InlineCode> right away:
                  </Callout>

                  <CodeBlock
                    filename=".gitignore"
                    code={`.env
venv/
__pycache__/`}
                    showLineNumbers={false}
                  />

                  <p className="text-muted-foreground leading-relaxed mt-4 mb-4">
                    Now load the key at the top of your Python file:
                  </p>

                  <CodeBlock
                    filename="chatbot.py"
                    code={`import os
from dotenv import load_dotenv

# Load environment variables from .env
load_dotenv()

# Verify the key is found
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("OPENAI_API_KEY not found. Check your .env file.")

print("âœ“ API key loaded successfully")`}
                  />

                  <OutputBlock
                    output={`âœ“ API key loaded successfully`}
                    title="Output"
                  />
                </div>
              </section>

              {/* ==================== IMPLEMENTATION ==================== */}
              <section id="implementation" className="mb-16">
                <h2 className="text-2xl font-bold text-foreground mb-4 flex items-center gap-3">
                  <button
                    onClick={() => toggleProgress('implementation')}
                    className="text-muted-foreground hover:text-teal-500 transition-colors"
                  >
                    {progress.includes('implementation') ? (
                      <CheckCircle2 className="w-6 h-6 text-teal-500" />
                    ) : (
                      <Circle className="w-6 h-6" />
                    )}
                  </button>
                  Implementation
                </h2>
                <p className="text-muted-foreground leading-relaxed mb-8">
                  We'll build the chatbot in layers, adding one feature at a time. By the end of this section
                  you'll have a streaming chatbot with persistent conversation memory.
                </p>

                {/* Step 1 â€” Basic Chat Call */}
                <div id="basic-chat" className="mb-12">
                  <h3 className="text-xl font-semibold text-foreground mb-4">Step 1 â€” Basic Chat Call</h3>
                  <p className="text-muted-foreground leading-relaxed mb-4">
                    Let's make our very first LLM call. We'll instantiate the <InlineCode>ChatOpenAI</InlineCode> model 
                    and send it a single message:
                  </p>

                  <CodeBlock
                    filename="chatbot.py"
                    code={`from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage

# Initialize the model
model = ChatOpenAI(
    model="gpt-4o-mini",   # Fast & affordable
    temperature=0.7,        # A bit of creativity
)

# Send a single message
response = model.invoke([
    HumanMessage(content="What is LangChain in one sentence?")
])

print(response.content)`}
                  />

                  <OutputBlock
                    output={`LangChain is a framework for building applications powered by large language models through composable chains, tools, and memory.`}
                    title="Output"
                  />

                  <p className="text-muted-foreground leading-relaxed mt-4">
                    That's it â€” one function call and you've got GPT talking back. But notice we sent a raw
                    list of messages. For a real chatbot we want a reusable template.
                  </p>
                </div>

                {/* Step 2 â€” Prompt Template */}
                <div id="prompt-template" className="mb-12">
                  <h3 className="text-xl font-semibold text-foreground mb-4">Step 2 â€” Prompt Templates</h3>
                  <p className="text-muted-foreground leading-relaxed mb-4">
                    A <InlineCode>ChatPromptTemplate</InlineCode> lets you define a reusable conversation
                    structure with a system prompt, a placeholder for history, and a slot for the user's
                    latest message:
                  </p>

                  <CodeBlock
                    filename="chatbot.py"
                    code={`from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

# Define the prompt template
prompt = ChatPromptTemplate.from_messages([
    (
        "system",
        "You are a helpful AI assistant called CodeBot. "
        "You are friendly, concise, and love helping people learn to code. "
        "If you don't know something, say so honestly.",
    ),
    MessagesPlaceholder(variable_name="history"),   # Chat history goes here
    ("human", "{input}"),                            # Latest user message
])

# Create a chain: prompt â†’ model
chain = prompt | model

# Test it (no history yet)
response = chain.invoke({
    "history": [],
    "input": "Hey! What can you do?"
})

print(response.content)`}
                  />

                  <OutputBlock
                    output={`Hey! ðŸ‘‹ I'm CodeBot. I can help you with:
â€¢ Explaining programming concepts
â€¢ Debugging code snippets
â€¢ Suggesting best practices
â€¢ Walking you through projects step by step

What would you like to learn today?`}
                    title="Output"
                  />

                  <Callout type="note">
                    The <InlineCode>|</InlineCode> (pipe) operator in LangChain creates a <strong>chain</strong>. 
                    Data flows left to right: the prompt is rendered first, then the result is sent to the model.
                    This composability is one of LangChain's super powers.
                  </Callout>
                </div>

                {/* Step 3 â€” Adding Memory */}
                <div id="adding-memory" className="mb-12">
                  <h3 className="text-xl font-semibold text-foreground mb-4">Step 3 â€” Adding Memory</h3>
                  <p className="text-muted-foreground leading-relaxed mb-4">
                    Right now our chain has no memory â€” every call is independent. Let's fix that by plugging
                    in <InlineCode>ChatMessageHistory</InlineCode> and wrapping the chain with 
                    <InlineCode>RunnableWithMessageHistory</InlineCode>:
                  </p>

                  <CodeBlock
                    filename="chatbot.py"
                    code={`from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory

# In-memory store: one history per session
store = {}

def get_session_history(session_id: str) -> ChatMessageHistory:
    """Return (or create) a history object for the given session."""
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]

# Wrap the chain with memory
chatbot = RunnableWithMessageHistory(
    chain,
    get_session_history,
    input_messages_key="input",
    history_messages_key="history",
)

# Configuration â€” identifies the session
config = {"configurable": {"session_id": "user-1"}}

# First message
r1 = chatbot.invoke({"input": "My name is Alex."}, config=config)
print("Bot:", r1.content)

# Second message â€” the model should remember the name
r2 = chatbot.invoke({"input": "What's my name?"}, config=config)
print("Bot:", r2.content)`}
                  />

                  <OutputBlock
                    output={`Bot: Nice to meet you, Alex! ðŸ‘‹ How can I help you today?
Bot: Your name is Alex! What would you like to work on?`}
                    title="Output"
                  />

                  <p className="text-muted-foreground leading-relaxed mt-4">
                    The chatbot remembers! Under the hood, <InlineCode>RunnableWithMessageHistory</InlineCode> fetches 
                    the stored messages and injects them into the <InlineCode>history</InlineCode> placeholder
                    of our prompt template before every call.
                  </p>

                  <Callout type="tip" title="Multiple sessions">
                    Change the <InlineCode>session_id</InlineCode> to start a separate conversation. Each
                    session has its own isolated history â€” just like real chat threads.
                  </Callout>
                </div>

                {/* Step 4 â€” Streaming Responses */}
                <div id="streaming" className="mb-12">
                  <h3 className="text-xl font-semibold text-foreground mb-4">Step 4 â€” Streaming Responses</h3>
                  <p className="text-muted-foreground leading-relaxed mb-4">
                    Waiting for the full response before showing anything feels sluggish. Let's stream tokens
                    to the terminal as the model generates them:
                  </p>

                  <CodeBlock
                    filename="chatbot.py"
                    code={`# Stream the response token-by-token
config = {"configurable": {"session_id": "user-1"}}

print("Bot: ", end="", flush=True)
for chunk in chatbot.stream({"input": "Explain Python decorators in 3 sentences."}, config=config):
    print(chunk.content, end="", flush=True)
print()  # newline at the end`}
                  />

                  <OutputBlock
                    output={`Bot: A decorator is a function that wraps another function to extend its behavior without modifying its source code. You apply it with the @decorator syntax above a function definition. Common uses include logging, authentication checks, and caching results.`}
                    title="Output (streamed token-by-token)"
                  />

                  <p className="text-muted-foreground leading-relaxed mt-4">
                    The only change was swapping <InlineCode>.invoke()</InlineCode> for <InlineCode>.stream()</InlineCode>. 
                    LangChain handles chunking automatically â€” each <InlineCode>chunk.content</InlineCode> is a small 
                    piece of the generated text.
                  </p>
                </div>
              </section>

              {/* ==================== COMPLETE CHATBOT ==================== */}
              <section id="complete-chatbot" className="mb-16">
                <h2 className="text-2xl font-bold text-foreground mb-4 flex items-center gap-3">
                  <button
                    onClick={() => toggleProgress('complete-chatbot')}
                    className="text-muted-foreground hover:text-teal-500 transition-colors"
                  >
                    {progress.includes('complete-chatbot') ? (
                      <CheckCircle2 className="w-6 h-6 text-teal-500" />
                    ) : (
                      <Circle className="w-6 h-6" />
                    )}
                  </button>
                  Complete Chatbot
                </h2>
                <p className="text-muted-foreground leading-relaxed mb-4">
                  Let's put everything together into a single, production-ready script. This version includes
                  a REPL loop so you can have a real conversation in your terminal:
                </p>

                <CodeBlock
                  filename="chatbot.py"
                  code={`"""
Basic Chatbot with LangChain & OpenAI
======================================
A conversational chatbot with memory and streaming.

Usage:
  1. Create a .env file with your OPENAI_API_KEY
  2. pip install langchain langchain-openai python-dotenv
  3. python chatbot.py
"""

import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory

# â”€â”€ 1. Load environment â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()

if not os.getenv("OPENAI_API_KEY"):
    raise ValueError("Set OPENAI_API_KEY in your .env file.")

# â”€â”€ 2. Initialize model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
model = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0.7,
    streaming=True,        # Enable streaming at the model level
)

# â”€â”€ 3. Define prompt template â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
prompt = ChatPromptTemplate.from_messages([
    (
        "system",
        "You are CodeBot, a friendly and concise AI assistant. "
        "You specialize in helping people learn programming and AI concepts. "
        "Keep your answers clear and to the point. "
        "If you don't know something, say so honestly.",
    ),
    MessagesPlaceholder(variable_name="history"),
    ("human", "{input}"),
])

# â”€â”€ 4. Create chain â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
chain = prompt | model

# â”€â”€ 5. Set up memory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
store = {}

def get_session_history(session_id: str) -> ChatMessageHistory:
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]

chatbot = RunnableWithMessageHistory(
    chain,
    get_session_history,
    input_messages_key="input",
    history_messages_key="history",
)

# â”€â”€ 6. Chat loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    session_id = "default"
    config = {"configurable": {"session_id": session_id}}

    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘         ðŸ¤–  CodeBot v1.0                 â•‘")
    print("â•‘  Type 'quit' to exit, 'clear' to reset   â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print()

    while True:
        user_input = input("You: ").strip()

        if not user_input:
            continue
        if user_input.lower() in ("quit", "exit", "q"):
            print("\\nGoodbye! ðŸ‘‹")
            break
        if user_input.lower() == "clear":
            store.pop(session_id, None)
            print("\\nâœ“ Conversation cleared.\\n")
            continue

        print("Bot: ", end="", flush=True)
        for chunk in chatbot.stream({"input": user_input}, config=config):
            print(chunk.content, end="", flush=True)
        print("\\n")

if __name__ == "__main__":
    main()`}
                />

                <Callout type="tip" title="That's only ~80 lines!">
                  Despite being short, this chatbot has everything: a system prompt persona, full conversation
                  memory, streaming output, and session management. LangChain handles the heavy lifting so you
                  can focus on the experience.
                </Callout>
              </section>

              {/* ==================== TESTING IT OUT ==================== */}
              <section id="testing" className="mb-16">
                <h2 className="text-2xl font-bold text-foreground mb-4 flex items-center gap-3">
                  <button
                    onClick={() => toggleProgress('testing')}
                    className="text-muted-foreground hover:text-teal-500 transition-colors"
                  >
                    {progress.includes('testing') ? (
                      <CheckCircle2 className="w-6 h-6 text-teal-500" />
                    ) : (
                      <Circle className="w-6 h-6" />
                    )}
                  </button>
                  Testing It Out
                </h2>
                <p className="text-muted-foreground leading-relaxed mb-4">
                  Run your chatbot and try a multi-turn conversation:
                </p>

                <CodeBlock
                  language="bash"
                  filename="terminal"
                  code={`python chatbot.py`}
                  showLineNumbers={false}
                />

                <OutputBlock
                  output={`â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         ðŸ¤–  CodeBot v1.0                 â•‘
â•‘  Type 'quit' to exit, 'clear' to reset   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

You: Hey! My name is Alex and I'm learning Python.
Bot: Hi Alex! ðŸ‘‹ Great to meet you. Python is an awesome first language â€” it's
readable, versatile, and has a huge community. What are you working on or
curious about right now?

You: What is a list comprehension?
Bot: A list comprehension is a concise way to create a new list by transforming
or filtering items from an existing iterable. Here's the pattern:

  new_list = [expression for item in iterable if condition]

For example: squares = [x**2 for x in range(10)] gives you [0, 1, 4, 9, ...].

Want me to show more examples, Alex?

You: Yes, with filtering!
Bot: Sure! Here's a list comprehension that filters even numbers:

  evens = [x for x in range(20) if x % 2 == 0]
  # â†’ [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]

And one that grabs words longer than 3 characters:

  words = ["hi", "hello", "hey", "howdy"]
  long_words = [w for w in words if len(w) > 3]
  # â†’ ["hello", "howdy"]

You: quit
Goodbye! ðŸ‘‹`}
                  title="Sample Conversation"
                />

                <p className="text-muted-foreground leading-relaxed mt-4">
                  Notice how the bot remembers your name ("Alex") across turns and refers back to it.
                  That's the memory system at work â€” every message you and the bot exchange is stored in 
                  <InlineCode>ChatMessageHistory</InlineCode> and injected into the next prompt.
                </p>

                {/* Project structure recap */}
                <div className="mt-8 p-6 rounded-2xl bg-card/50 border border-border">
                  <h4 className="font-semibold text-foreground mb-3">Project structure</h4>
                  <CodeBlock
                    filename="tree"
                    code={`chatbot/
â”œâ”€â”€ .env              # Your OpenAI API key
â”œâ”€â”€ .gitignore        # Ignore .env, venv, __pycache__
â”œâ”€â”€ chatbot.py        # The complete chatbot (80 lines)
â””â”€â”€ venv/             # Virtual environment (optional)`}
                    showLineNumbers={false}
                  />
                </div>
              </section>

              {/* ==================== NEXT STEPS ==================== */}
              <section id="next-steps" className="mb-16">
                <h2 className="text-2xl font-bold text-foreground mb-4 flex items-center gap-3">
                  <button
                    onClick={() => toggleProgress('next-steps')}
                    className="text-muted-foreground hover:text-teal-500 transition-colors"
                  >
                    {progress.includes('next-steps') ? (
                      <CheckCircle2 className="w-6 h-6 text-teal-500" />
                    ) : (
                      <Circle className="w-6 h-6" />
                    )}
                  </button>
                  Next Steps
                </h2>
                <p className="text-muted-foreground leading-relaxed mb-6">
                  Congratulations â€” you've built a fully functional chatbot with memory and streaming!
                  Here's where to go next:
                </p>

                <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
                  <Link to="/docs/basic-rag" className="group p-6 rounded-2xl bg-card/50 border border-border hover:border-foreground/20 hover:shadow-lg hover:shadow-foreground/5 transition-all">
                    <div>
                      <h3 className="font-semibold text-foreground mb-1 group-hover:text-teal-500 transition-colors">
                        Implement Basic RAG
                      </h3>
                      <p className="text-sm text-muted-foreground">
                        Give your chatbot knowledge by connecting it to documents
                      </p>
                    </div>
                  </Link>

                  <Link to="/docs/small-agent" className="group p-6 rounded-2xl bg-card/50 border border-border hover:border-foreground/20 hover:shadow-lg hover:shadow-foreground/5 transition-all">
                    <div>
                      <h3 className="font-semibold text-foreground mb-1 group-hover:text-teal-500 transition-colors">
                        Build a Small Agent
                      </h3>
                      <p className="text-sm text-muted-foreground">
                        Add tool use and autonomous reasoning to your bot
                      </p>
                    </div>
                  </Link>

                  <Link to="/docs/prompt-engineering" className="group p-6 rounded-2xl bg-card/50 border border-border hover:border-foreground/20 hover:shadow-lg hover:shadow-foreground/5 transition-all">
                    <div>
                      <h3 className="font-semibold text-foreground mb-1 group-hover:text-teal-500 transition-colors">
                        Prompt Engineering Patterns
                      </h3>
                      <p className="text-sm text-muted-foreground">
                        Make your system prompt more reliable with proven techniques
                      </p>
                    </div>
                  </Link>

                  <Link to="/docs/model-deployment" className="group p-6 rounded-2xl bg-card/50 border border-border hover:border-foreground/20 hover:shadow-lg hover:shadow-foreground/5 transition-all">
                    <div>
                      <h3 className="font-semibold text-foreground mb-1 group-hover:text-teal-500 transition-colors">
                        Model Deployment
                      </h3>
                      <p className="text-sm text-muted-foreground">
                        Deploy your chatbot as an API or web app
                      </p>
                    </div>
                  </Link>
                </div>
              </section>

              {/* Footer Navigation */}
              <div className="flex items-center justify-between pt-8 border-t border-border">
                <Link to="/docs" className="flex items-center gap-2 text-muted-foreground hover:text-foreground transition-colors">
                  <ArrowLeft className="w-4 h-4" />
                  Back to Docs
                </Link>
                <a
                  href="https://github.com"
                  target="_blank"
                  rel="noopener noreferrer"
                  className="flex items-center gap-2 text-muted-foreground hover:text-foreground transition-colors"
                >
                  Edit on GitHub
                  <ExternalLink className="w-4 h-4" />
                </a>
              </div>
            </article>

            {/* Right Sidebar - On This Page (Desktop) */}
            <aside className="hidden xl:block w-56 shrink-0">
              <div className="sticky top-28">
                <div className="flex items-center gap-2 mb-4">
                  <List className="w-4 h-4 text-muted-foreground" />
                  <span className="text-sm font-medium text-foreground">On this page</span>
                </div>
                <nav className="space-y-1 mb-6">
                  {sections.map((section) => (
                    <button
                      key={section.id}
                      onClick={() => scrollToSection(section.id)}
                      className={`block w-full text-left text-sm py-1.5 transition-colors ${
                        section.parent ? 'pl-4' : ''
                      } ${
                        activeSection === section.id
                          ? 'text-teal-500 font-medium'
                          : 'text-muted-foreground hover:text-foreground'
                      }`}
                    >
                      {section.title}
                    </button>
                  ))}
                </nav>
              </div>
            </aside>
          </div>
        </div>
      </main>

      <Footer />
    </div>
  );
};

export default BasicChatbot;
